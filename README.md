# Awesome-Compositional-Zero-Shot

Papers and codes about Compositional Zero Shot Learning(CZSL) for computer vision are present on this page. Besides, the commonly-used datasets for CZSL are also introduced. 

## Looking for Contributors!

I'm looking for collaborators interested in helping community maintain and update this list. If you're interested in adding new CZSL-related papers, please email me!

Thanks!

##  Papers

### 2025
| Title                                                                                      |   Venue   |                                                                              PDF                                                                               |                      CODE                      |
|:------------------------------------------------------------------------------------------ |:---------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------:|
| TOMCAT: Test-time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning | NeurIPS 2025 | [PDF](https://arxiv.org/abs/2510.20162) | - |
| Learning Visual Proxy for Compositional Zero-Shot Learning | ICCV 2025 | - | - |
| ZFusion: Efficient Deep Compositional Zero-shot Learning for Blind Image Super-Resolution with Generative Diffusion Prior | ICCV 2025 | - | - |
| Zero-Shot Compositional Video Learning with Coding Rate Reduction | ICCV 2025 | - | - |
| A Conditional Probability Framework for Compositional Zero-shot Learning | ICCV 2025 | - | - |
| Beyond Image Classification: A Video Benchmark and Dual-Branch Hybrid Discrimination Framework for Compositional Zero-Shot Learning | CVPR 2025 | [PDF](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_Beyond_Image_Classification_A_Video_Benchmark_and_Dual-Branch_Hybrid_Discrimination_CVPR_2025_paper.pdf) | - |
| LOGICZSL: Exploring Logic-induced Representation for Compositional Zero-shot Learning | CVPR 2025 | [PDF](https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_LOGICZSL_Exploring_Logic-induced_Representation_for_Compositional_Zero-shot_Learning_CVPR_2025_paper.pdf) | [CODE](https://github.com/Pieux0/LOGICZSL) |
| Learning Clustering-based Prototypes for Compositional Zero-shot Learning | ICLR 2025 | [PDF](https://arxiv.org/abs/2502.06501) | [CODE](https://github.com/quhongyu/ClusPro) |
| AOGN-CZSL: An Attribute- and Object-Guided Network for Compositional Zero-Shot Learning | IF 2025 | [PDF](https://www.sciencedirect.com/science/article/pii/S1566253525001691) | - |
| Adaptive Fusion Learning for Compositional Zero-Shot Recognition | TMM 2025 | [PDF](https://ieeexplore.ieee.org/abstract/document/10814709) | - |
| Compact Latent Primitive Space Learning for Compositional Zero-Shot Learning | TMM 2025 | [PDF](https://ieeexplore.ieee.org/abstract/document/10855509) | - |
| Concept-Aware Graph Convolutional Network for Compositional Zero-Shot Learning | TNNLS 2025 | [PDF](https://ieeexplore.ieee.org/abstract/document/10856526) | - |


### 2024
| Title                                                                                      |   Venue   |                                                                              PDF                                                                               |                      CODE                      |
|:------------------------------------------------------------------------------------------ |:---------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------:|
| Imaginary-Connected Embedding in Complex Space for Unseen Attribute-Object Discrimination | TPAMI 2024 | [PDF](https://ieeexplore.ieee.org/abstract/document/10737702) | [CODE](https://github.com/LanchJL/IMAX) |
| Disentangling Before Composing: Learning Invariant Disentangled Features for Compositional Zero-Shot Learning | TPAMI 2024 | [PDF](https://ieeexplore.ieee.org/abstract/document/10737100) | [CODE](https://github.com/PRIS-CV/Disentangling-before-Composing) |
| Simple Primitives With Feasibility- and Contextuality-Dependence for Open-World Compositional Zero-Shot Learning | TPAMI 2024 | [PDF](https://ieeexplore.ieee.org/document/10274865?denied=) | - |
| C2C: Component-to-Composition Learning for Zero-Shot Compositional Action Recognition | ECCV 2024 | [PDF](https://arxiv.org/abs/2407.06113) | [CODE](https://github.com/RongchangLi/ZSCAR_C2C) |
| Prompting Language-Informed Distribution for Compositional Zero-Shot Learning | ECCV 2024 | [PDF](https://arxiv.org/abs/2305.14428) | [CODE](https://github.com/Cogito2012/PLID) |
| MRSP: Learn Multi-representations of Single Primitive for Compositional Zero-Shot Learning | ECCV 2024 | [PDF](https://link.springer.com/chapter/10.1007/978-3-031-73650-6_1#Sec8) | - |
| Understanding Multi-compositional learning in Vision and Language models via Category Theory | ECCV 2024 | [PDF](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06472.pdf) | [CODE](https://github.com/SPChytas/CatCom) |
| Beyond Seen Primitive Concepts for Attributes-Objects Compositional Learning | CVPR 2024 | [PDF](https://www.cs.umd.edu/~nirat/beyond_seen_concepts.pdf) | - |
| Context-based and Diversity-driven Specificity in Compositional Zero-Shot Learning | CVPR 2024 | [PDF](https://arxiv.org/abs/2402.17251) | - |
| Troika: Multi-Path Cross-Modal Traction for Compositional Zero-Shot Learning | CVPR 2024 | [PDF](https://arxiv.org/abs/2303.15230) | - |
| Retrieval-Augmented Primitive Representations for Compositional Zero-Shot Learning | AAAI 2024 | [PDF](https://ojs.aaai.org/index.php/AAAI/article/view/28043) | - |
| ProCC: Progressive Cross-primitive Compatibility for Open-World Compositional Zero-Shot Learning | AAAI 2024 | [PDF](https://ojs.aaai.org/index.php/AAAI/article/view/29164) | [CODE](https://github.com/huofushuo/procc) |
| Revealing the Proximate Long-Tail Distribution in Compositional Zero-Shot Learning | AAAI 2024 | [PDF](https://ojs.aaai.org/index.php/AAAI/article/view/28026) | - |
| A Dynamic Learning Method towards Realistic Compositional Zero-Shot Learning | AAAI 2024 | [PDF](https://ojs.aaai.org/index.php/AAAI/article/view/28000) | - |
| Continual Compositional Zero-Shot Learning | IJCAI 2024 | [PDF](https://www.ijcai.org/proceedings/2024/0191.pdf) | - |
| CSCNET: Class-Specified Cascaded Network for Compositional Zero-Shot Learning | ICASSP 2024 | [PDF](https://ieeexplore.ieee.org/abstract/document/10638107) | [CODE](https://github.com/Yanyi-Zhang/CSCNet) |
| Learning Conditional Prompt for Compositional Zero-Shot Learning | ICME 2024 | [PDF](https://ieeexplore.ieee.org/abstract/document/10688263/authors#authors) | - |
| PMGNet: Disentanglement and entanglement benefit mutually for compositional zero-shot learning | CVIU 2024 | [PDF](https://www.sciencedirect.com/science/article/abs/pii/S1077314224002789) | - |
| LVAR-CZSL: Learning Visual Attributes Representation for Compositional Zero-Shot Learning | TCSVT 2024 | [PDF](https://arxiv.org/abs/2403.05924) | [CODE](https://github.com/mxjmxj1/LVAR-CZSL) |
| Agree to Disagree: Exploring Partial Semantic Consistency against Visual Deviation for Compositional Zero-Shot Learning | TCDS 2024 | [PDF](https://ieeexplore.ieee.org/document/10440562) | - |
| Compositional Zero-Shot Learning using Multi-Branch Graph Convolution and Cross-layer Knowledge Sharing | PR 2024 | [PDF](https://www.sciencedirect.com/science/article/pii/S0031320323006143) | - |
| Visual primitives as words: Alignment and interaction for compositional zero-shot learning | PR 2024 | [PDF](https://www.sciencedirect.com/science/article/pii/S003132032400565X) | - |
| Mutual Balancing in State-Object Components for Compositional Zero-Shot Learning | PR 2024 | [PDF](https://www.sciencedirect.com/science/article/pii/S0031320324002024) | - |
| GIPCOL: Graph-Injected Soft Prompting for Compositional Zero-ShotLearning | WACV 2024 | [PDF](https://arxiv.org/pdf/2311.05729.pdf) | [CODE](https://github.com/HLR/GIPCOL) |
| CAILA: Concept-Aware Intra-Layer Adapters for Compositional Zero-Shot Learning | WACV 2024 | [PDF](https://openaccess.thecvf.com/content/WACV2024/html/Zheng_CAILA_Concept-Aware_Intra-Layer_Adapters_for_Compositional_Zero-Shot_Learning_WACV_2024_paper.html) | - |


### 2023
| Title                                                                                      |   Venue   |                                                                              PDF                                                                               |                      CODE                      |
|:------------------------------------------------------------------------------------------ |:---------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------:|
| Distilled Reverse Attention Network for Open-world Compositional Zero-Shot Learning | ICCV 2023 | [PDF](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Distilled_Reverse_Attention_Network_for_Open-world_Compositional_Zero-Shot_Learning_ICCV_2023_paper.pdf) | - |
| Hierarchical Visual Primitive Experts for Compositional Zero-Shot Learning | ICCV 2023 | [PDF](https://arxiv.org/pdf/2308.04016.pdf) | [CODE](https://github.com/HanjaeKim98/CoT) |
| Do Vision-Language Pretrained Models Learn Composable Primitive Concepts? | TMLR 2023 | [PDF](https://arxiv.org/pdf/2203.17271.pdf) |  [CODE](https://github.com/tttyuntian/vlm_primitive_concepts) |
| Reference-Limited Compositional Zero-Shot Learning | ICMR 2023 | [PDF](https://arxiv.org/pdf/2208.10046) |   [CODE](-)   |
| Learning Conditional Attributes for Compositional Zero-Shot Learning | CVPR 2023 | [PDF](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Learning_Conditional_Attributes_for_Compositional_Zero-Shot_Learning_CVPR_2023_paper.pdf) |   [CODE](https://github.com/wqshmzh/CANet-CZSL)   |
| Learning Attention as Disentangler for Compositional Zero-shot Learning | CVPR 2023 | [PDF](https://arxiv.org/abs/2303.15111) |   [CODE](https://github.com/haoosz/ade-czsl)   |
| Decomposed Soft Prompt Guided Fusion Enhancing for Compositional Zero-Shot Learning | CVPR 2023 | [PDF](https://arxiv.org/abs/2211.10681)|   [CODE](https://github.com/Forest-art/DFSP)   |
| Learning to Compose Soft Prompts for Compositional Zero-Shot Learning  | ICLR 2023 | [PDF](https://openreview.net/pdf?id=S8-A2FXnIh) |   [CODE](https://github.com/BatsResearch/csp)   |
| Compositional Zero-Shot Artistic Font Synthesis | IJCAI 2023 | [PDF](https://www.ijcai.org/proceedings/2023/122) |   [CODE](-)   |
| Hierarchical Prompt Learning for Compositional Zero-Shot Recognition  | IJCAI 2023 | [PDF](https://www.ijcai.org/proceedings/2023/163) |   -   |
| Leveraging Sub-Class Discrimination for Compositional Zero-shot Learning | AAAI 2023 | [PDF](https://doi.org/10.1609/aaai.v37i1.25168)|   [CODE](https://github.com/hxm97/SCD-CZSL)   |
| Dual-Stream Contrastive Learning for Compositional Zero-Shot Recognition | TMM 2023 | [PDF](https://ieeexplore.ieee.org/abstract/document/10044268)|   -   |
| Isolating Features of Object and Its State for Compositional Zero-Shot Learning | TETCI 2023 | [PDF](https://ieeexplore.ieee.org/document/10015197)|    -    |
| Learning Attention Propagation for Compositional Zero-Shot Learning | WACV 2023 | [PDF](https://openaccess.thecvf.com/content/WACV2023/papers/Khan_Learning_Attention_Propagation_for_Compositional_Zero-Shot_Learning_WACV_2023_paper.pdf)|    -    |


### 2022
| Title                                                                                      |   Venue   |                                                                              PDF                                                                               |                      CODE                      |
|:------------------------------------------------------------------------------------------ |:---------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------:|
| A Decomposable Causal View of Compositional Zero-Shot Learning                             | TMM 2022  | [PDF](https://ieeexplore.ieee.org/document/9864072/metrics#metrics)                                                      |   [CODE](https://github.com/muliyangm/DeCa)    |
| KG-SP: Knowledge Guided Simple Primitives for Open World Compositional Zero-Shot Learning | CVPR 2022 | [PDF](http://arxiv.org/pdf/2205.06784)                                                                                   | [CODE](https://github.com/explainableml/kg-sp) |
| Disentangling Visual Embeddings for Attributes and Objects                                 | CVPR 2022 | [PDF](https://arxiv.org/pdf/2205.08536.pdf)                                                                              |   [CODE](https://github.com/nirat1606/oadis)   |
| Siamese Contrastive Embedding Network for Compositional Zero-Shot Learning                 | CVPR 2022 | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Siamese_Contrastive_Embedding_Network_for_Compositional_Zero-Shot_Learning_CVPR_2022_paper.pdf) | [CODE](https://github.com/XDUxyLi/SCEN-master) |
| On Leveraging Variational Graph Embeddings for Open World Compositional Zero-Shot Learning | ACM MM 2022 | [PDF](https://arxiv.org/abs/2204.11848)                                                                                   | -  |
| 3D Compositional Zero-shot Learning with DeCompositional Consensus                         | ECCV 2022 | [PDF](https://arxiv.org/pdf/2111.14673.pdf)                                                                              | [CODE](https://github.com/ferjad/3DCZSL)    |
| Learning Invariant Visual Representations for Compositional Zero-Shot Learning            | ECCV 2022 | [PDF](https://arxiv.org/pdf/2206.00415.pdf)                                                                              | [CODE](https://github.com/PRIS-CV/IVR)    |
| Learning Graph Embeddings for Open World Compositional Zero-Shot Learning                 | TPAMI 2022 | [PDF](https://arxiv.org/pdf/2105.01017)                                                                                  | - |
| Bi-Modal Compositional Network for Feature Disentanglement                                | ICIP 2022 | [PDF](https://ieeexplore.ieee.org/document/9897457)                                                                      | - |



### 2021

 


### 2020
| Title                                                                                 |    Venue     |                                                                          PDF                                                                          |                        CODE                        |
|:------------------------------------------------------------------------------------- |:------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------:|
| Learning Graph Embeddings for Compositional Zero-Shot Learning                        |  CVPR 2021   | [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Naeem_Learning_Graph_Embeddings_for_Compositional_Zero-Shot_Learning_CVPR_2021_paper.pdf) |   [CODE](https://github.com/ExplainableML/czsl)    |
| Open World Compositional Zero-Shot Learning                                           |  CVPR 2021   | [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9578210)                                        |   [CODE](https://github.com/ExplainableML/czsl)    |
| Independent Prototype Propagation for Zero-Shot Compositionality                      | NeurIPS 2021 | [PDF](https://arxiv.org/pdf/2106.00305.pdf)                                                      |   [CODE](https://github.com/FrankRuis/ProtoProp)   |
| Revisiting Visual Product for Compositional Zero-Shot Learning                      | NeurIPS 2021 | [PDF](https://openreview.net/pdf?id=Yc9Vh1nn-2I)                                  |   -   |
| Learning Single/Multi-Attribute of Object with Symmetry and Group                     |  TPAMI 2021  | [PDF](https://arxiv.org/pdf/2110.04603)                                                        |  [CODE](https://github.com/DirtyHarryLYL/SymNet)   |
| Relation-aware Compositional Zero-shot Learning for Attribute-Object Pair Recognition | TMM 2021 | [PDF](https://arxiv.org/pdf/2108.04603) | [CODE](https://github.com/daoyuan98/Relation-CZSL) |
| A Contrastive Learning Approach for Compositional Zero-Shot Learning | ICMI 2021 | [PDF](https://dl.acm.org/doi/abs/10.1145/3462244.3479904) | - |


### 2019
| Title                                                                                 |   Venue   |                                                                PDF                                                                |                            CODE                             |
|:------------------------------------------------------------------------------------- |:---------:|:---------------------------------------------------------------------------------------------------------------------------------:|:-----------------------------------------------------------:|
| Adversarial Fine-Grained Composition Learning for Unseen Attribute-Object Recognition | ICCV 2019 | [PDF](https://see.xidian.edu.cn/faculty/chdeng/Welcome%20to%20Cheng%20Deng's%20Homepage_files/Papers/Conference/ICCV2019_Kun.pdf) |                              -                              |
| Task-Driven Modular Networks for Zero-Shot Compositional Learning                     | ICCV 2019 | [PDF](https://ieeexplore.ieee.org/document/9010265)                                        | [CODE](https://github.com/facebookresearch/taskmodularnets) |
| Recognizing Unseen Attribute-Object Pair with Generative Model | AAAI 2019 | [PDF](https://ojs.aaai.org/index.php/AAAI/article/view/4907) | - |


### 2018
| Title                                          |   Venue   |                                      PDF                                      |                            CODE                             |
|:---------------------------------------------- |:---------:|:----------------------------------------------------------------------------:|:-----------------------------------------------------------:|
| Attributes as Operators: Factorizing Unseen Attribute-Object Compositions | CVPR 2018 | [PDF](https://arxiv.org/pdf/1803.09851.pdf) | [CODE](https://github.com/Tushar-N/attributes-as-operators) |


### 2017
| Title                                          |   Venue   |                                      PDF                                      |                            CODE                             |
|:---------------------------------------------- |:---------:|:----------------------------------------------------------------------------:|:-----------------------------------------------------------:|
| From Red Wine to Red Tomato: Composition with Context | CVPR 2017 | [PDF](https://ieeexplore.ieee.org/document/8099612) | [CODE](https://github.com/imisra/composing_cvpr17) |

##  Datasets

Most CZSL papers usually conduct experiments on MIT-States and UT-Zappos datasets. However, as CZSL receives more attention, some new datasets are proposed and used in recent papers, such as C-GQA, AO-CLEVr, etc.

### MIT-States

Introduced by Isola et al. in  [Discovering States and Transformations in Image Collections](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7298744).

The MIT-States dataset has 245 object classes, 115 attribute classes and ∼53K images. There is a wide range of objects (e.g., fish, persimmon, room) and attributes (e.g., mossy, deflated, dirty). On average, each object instance is modified by one of the 9 attributes it affords.

Source:http://web.mit.edu/phillipi/Public/states_and_transformations/index.html

### UT-Zappos

Introduced by Yu et al. in [Fine-Grained Visual Comparisons with Local Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6909426).

UT Zappos50K (UT-Zap50K) is a large shoe dataset consisting of 50,025 catalog images collected from  [Zappos.com](https://www.zappos.com/). The images are divided into 4 major categories — shoes, sandals, slippers, and boots — followed by functional types and individual brands. The shoes are centered on a white background and pictured in the same orientation for convenient analysis.

Source:https://vision.cs.utexas.edu/projects/finegrained/utzap50k/

### C-GQA

Introduced by Naeem et al. in [Learning Graph Embeddings for Compositional Zero-shot Learning](https://openaccess.thecvf.com/content/CVPR2021/papers/Naeem_Learning_Graph_Embeddings_for_Compositional_Zero-Shot_Learning_CVPR_2021_paper.pdf).

Compositional GQA (C-GQA) dataset is curated from the recent Stanford [GQA](https://cs.stanford.edu/people/dorarad/gqa/) dataset originally proposed for VQA.  C-GQA includes 413 attribute classes and 674 object classes, contains over 9.5k compositional labels with diverse compositional classes and clean annotations, making it the most extensive dataset for CZSL.

Source:https://github.com/ExplainableML/czsl

### AO-CLEVr

Introduced by Atzmon et al. in [A causal view of compositional zero-shot recognition](https://proceedings.neurips.cc/paper/2020/hash/1010cedf85f6a7e24b087e63235dc12e-Abstract.html).

AO-CLEVr is a new synthetic-images dataset containing images of "easy" Attribute-Object categories, based on the CLEVr. AO-CLEVr has attribute-object pairs created from 8 attributes: { red, purple, yellow, blue, green, cyan, gray, brown } and 3 object shapes {sphere, cube, cylinder}, yielding 24 attribute-object pairs. Each pair consists of 7500 images. Each image has a single object that consists of the attribute-object pair. The object is randomly assigned one of two sizes (small/large), one of two materials (rubber/metallic), a random position, and random lightning according to CLEVr defaults.

Source:https://github.com/nv-research-israel/causal_comp

### VAW-CZSL

Introduced by Nirat Saini et al. in [Disentangling Visual Embeddings for Attributes and Objects](https://arxiv.org/pdf/2205.08536.pdf).

VAW-CZSL, a subset of VAW, which is a multilabel attribute-object dataset. Sample one attribute per image, leading to much larger dataset in comparison to previous datasets. The images in the VAW dataset come from the [Visual Genome dataset](https://visualgenome.org/) which is also the source of the images in the [GQA](https://cs.stanford.edu/people/dorarad/gqa/about.html) and the [VG-Phrasecut](https://github.com/ChenyunWu/PhraseCutDataset) datasets.

Source:https://github.com/nirat1606/OADis.

### Compositional PartNet

Introduced by Naeem et al. in [3D Compositional Zero-shot Learning with DeCompositional Consensus](https://arxiv.org/pdf/2111.14673).

Compositional PartNet (C-PartNet) is refined from [PartNet](https://partnet.cs.stanford.edu) with a new labeling scheme that relates the compositional knowledge between objects by merging and renaming the repeated labels. The relabelled C-PartNet consists of 96 parts compared to 128 distinct part labels in the original PartNet.

Source:https://github.com/ferjad/3DCZSL
